{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks for Data Science Applications (2019/2020)\n",
    "## Final exam\n",
    "\n",
    "* **Student(s)**: Nurassilova Omirbanu (1848425).\n",
    "* **Reference paper**: Johnson R., Zhang T., 2015. Effective Use of Word Order for Text Categorizationwith Convolutional Neural Networks.\n",
    "\n",
    "\n",
    "\n",
    "## Part 1: Report\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "Convolutional Neural Network (CNN) was used in order to implement text categorization such as sentiment classification and topic categorization.  This task is done with texts which written  in natural languages with pre-defined categories. The code for this paper was written in c++ in 2015. And it was released as a tool on their web-site.\n",
    "\n",
    "Previous works used bag-of-word vectors to represent text documents (text embedding), where we take into account if words exist in the document or not. But we lose word order which is important in sentiment classification. There were methods to keep word order by using n-grams (sequence of n words as one unit), but it was not effective also.\n",
    "\n",
    "##### Novelty\n",
    "\n",
    "1. The main novelties are that authors use convolutional neural networks(CNN):\n",
    "    1. to keep word order\n",
    "    2. to have word embedding as a part of the training of the whole network. They donâ€™t use external word embedders.\n",
    "2. The technical novelty of using dynamic max-pooling layer to get constant sized output. We need it because text documents size varies, while finally, fully connected layers need constant sized input  to construct classifiers.\n",
    "\n",
    "\n",
    "##### used dataset\n",
    "In this paper several databases were studied. For this project IMDB data was used. This dataset contains 50k entries of data with positive and negative comments about movies. In our case model should predict if text contains positive or negative review. We tried to reimplement small experiments with two variants of input structure in python using Tensorflow. They are seq-CNN and bow-CNN for text. Text was cleaned and top 30k words were saved. But in order to reduce computation time we used only 5k words. For each word in the text we will have one vector with dim (5k,1) where all the entries will be zeros and only one value equal to 1 if this word is in top 5k list otherwise 0. So for each text we will have a matrix with dimension (number of words in one document, 5k).\n",
    "\n",
    "#### Experiments\n",
    "\n",
    "The standard CNN structure was used to compute convolutions for small regions vectors by moving orderly along input data. As an input they take 1D structured documents with initial word order, where a small region vectors corresponds to a sequence of words. To transform sequence of words to region vectors they had two methods: seq-CNN and bow-CNN. Sequences of words are taken as on the picture below:\n",
    "\n",
    "![seq_words](conseq.png)\n",
    "\n",
    "#### seq-CNN for text\n",
    "\n",
    "In this case input organized in a way where two vectors of two consequtive words concatenated on axis 1 and we have as input for convolution vector with dimension (2*length of the vector of one word, 1). So we can say that our region size is 2. Of course it can be other values but it makes the computation time more. The stride value should be 1 in this case. The main idea of this type of organization of the input is to save the order of words in the text. The window size in convolutional layer is 1 for this CNN.\n",
    "\n",
    "#### bow-CNN for text\n",
    "\n",
    "We have a problem related to the size of the input in the previous seq-CNN because of the value of region size r. The size of the input will be multiplied with r. In order to prevent having so huge matrixes we can use another variation offered in this paper. If we are assuming that the region size is 2 then we can put window size equal to region size in tensorflow function for creating convolutional layer of the network. In this way we can keep the idea to take each consequent pair of words vectors going together to convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: External libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import string\n",
    "from multiprocessing import Pool\n",
    "import operator\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# https://ai.stanford.edu/~amaas/data/sentiment/ \n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1848425*9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implementation\n",
    "\n",
    "1. Data cleaning part contains converting words to lowercase letters, then removing punctuation and stemmimg.\n",
    "2. Then words were sorted by their occurences in texts, the most popular 30k was saved into file.\n",
    "3. Experiments part contains implementation of two CNN with different versions of input matrixes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_words(path):\n",
    "    file = open(path, 'rt')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    # split into words\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    #print(tokens[:100], '\\n')\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    #print(\"without punctuations: \", stripped[:100], '\\n')\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    #print(\"not alph: \", words[:100], '\\n')\n",
    "    # filter out stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    #words = [w for w in words if not w in names_authors_lower]\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    #print(\"without stop words: \", words[:100], '\\n')\n",
    "    #find bigram\n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_list = [\"train\", \"test\"]\n",
    "word_count_dict = {}\n",
    "all_text ={}\n",
    "\n",
    "\n",
    "def word_cleaner(text_set):\n",
    "    root_path = os.path.join(\"aclImdb\", text_set)\n",
    "    all_text[text_set]= {}\n",
    "    for path, _, fnames in os.walk(root_path):\n",
    "        print(path)\n",
    "        pbar = tqdm(total=25000, desc = \"total {} set number: {}\".format(text_set, 25000))\n",
    "        for fname in fnames:\n",
    "            if fname.endswith(\"txt\"):\n",
    "                path_file = os.path.join(path,fname)\n",
    "                text = cleaning_words(path_file)\n",
    "                sense = path.split(\"/\")[-1]\n",
    "                if sense not in all_text[text_set]:\n",
    "                    all_text[text_set][sense]={}\n",
    "                \n",
    "                all_text[text_set][sense][fname] = text\n",
    "                #save_path = os.path.join(\"processed\", text_set,sense )\n",
    "                #os.makedirs(save_path, exist_ok = True)\n",
    "                #with open(os.path.join(save_path,fname), \"w\") as file:\n",
    "                    #file.write(text)\n",
    "                \n",
    "                \n",
    "                for word in text:\n",
    "                    if not word in word_count_dict:\n",
    "                        word_count_dict[word] = 1\n",
    "                    else:\n",
    "                        word_count_dict[word] += 1\n",
    "                pbar.update(1)\n",
    "                \n",
    "        pbar.close()\n",
    "                        \n",
    "for text_dir in set_list:\n",
    "    word_cleaner(text_dir)\n",
    "with open('word_count_dict.json', 'w') as f:\n",
    "    json.dump(word_count_dict, f)\n",
    "with open('all_text.json', 'w') as f:\n",
    "    json.dump(all_text, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sorting data\n",
    "getting top 30k popular words among texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_count_dict.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "sorted_data  = {k: v for k, v in sorted(data.items(), key=lambda item: item[1],reverse=True)}\n",
    "del sorted_data['br']\n",
    "del sorted_data['nt']\n",
    "top_30K_words_dict = dict(list(sorted_data.items())[:30000])\n",
    "\n",
    "list_words = list(sorted_data.keys())[:30000]\n",
    "top_30K_words ={}\n",
    "for i in range(30000):\n",
    "    top_30K_words[list_words[i]] = i\n",
    "    \n",
    "with open(\"top_30K_words_dict.json\", \"w\") as f:\n",
    "    json.dump(top_30K_words_dict, f)\n",
    "with open(\"top_30K_words.json\", \"w\") as f:\n",
    "    json.dump(top_30K_words, f)\n",
    "with open('all_text.json') as json_file:\n",
    "    all_text = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Taking the data that are processed in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_text.json') as json_file:\n",
    "    all_text = json.load(json_file)\n",
    "with open('top_30K_words.json') as json_file:\n",
    "    top_30K_words = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNN = 5000\n",
    "top_5K = dict(list(top_30K_words.items())[:NNN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project 5000 most popular words among texts in our dataset were chosen.\n",
    "\n",
    "Our dataset contained 50k texts.\n",
    "For train we took 20k of them.\n",
    "and For test 4k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = np.random.choice(list(all_text['train']['pos'].keys()),10000)\n",
    "neg_list = np.random.choice(list(all_text['train']['neg'].keys()),10000)\n",
    "pos_list_test = np.random.choice(list(all_text['test']['pos'].keys()),2000)\n",
    "neg_list_test = np.random.choice(list(all_text['test']['neg'].keys()),2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = [1]*2000\n",
    "tt = [0]*2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label.extend(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_l = []\n",
    "for x in pos_list_test:\n",
    "    lens_l.append(len(all_text['test']['pos'][x]))\n",
    "for x in neg_list_test:\n",
    "    lens_l.append(len(all_text['test']['neg'][x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = list(pos_list_test)\n",
    "test_set.extend(neg_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could not implement dynamic max_pooling as it is done in paper because we had retracing warning in executing training the model with different dimensions of input as authors of the paper did. That is why we decided to use the same dimension of inputs. In order to do that we added zero vectors to the text matrixes that we have. But we needed to decide which number to take.\n",
    "In order to define the dimension value (the length of the text that we will consider) we looked to lengthes of all texts. As we see below the max length is 1168, but it doesnot make sense to use this number and produce huge matrixes. At the end we picked 450 as the constant first dimension of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_list = [] # we calculated all lengthes in order to decide which number use to limit dimestion of our matrixes\n",
    "for x in pos_list:\n",
    "    lens_list.append(len(all_text['train']['pos'][x]))\n",
    "for x in neg_list:\n",
    "    lens_list.append(len(all_text['train']['neg'][x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(lens_list, 0.98) # we looked to the quantile, so we decided to use 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406.02"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(lens_l, 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(lens_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# the following method is calculating accuracy\n",
    "def pred_error(y,y_pred):    \n",
    "    conf_mat = confusion_matrix(y,y_pred)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y, y_pred)\n",
    "    err = 1-accuracy\n",
    "    return err, conf_mat, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq-CNN\n",
    "#### first model\n",
    "According to the paper network should have input,convolution, maxpooling and output layer.\n",
    "The following functions perform several tasks. Here the input matrix is concatenated with itself but from the second row by axis 1 in order to implement sequential CNN where order of words is saved and input of convolution is each pair of consequtive words in the text. We will put kernel size as 1 so convolutional layer will consider one row of the matrix at a time. Each row looks like the example above:\n",
    "\n",
    "![seq-input](seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_selection_train(): # this procedure takes sample at random from the train set\n",
    "    z = np.random.uniform()\n",
    "    if z>0.5:\n",
    "        text_id = np.random.choice(pos_list, 1)\n",
    "        sense = \"pos\"\n",
    "        \n",
    "    else: \n",
    "        text_id = np.random.choice(neg_list, 1)\n",
    "        sense = \"neg\"\n",
    "    return (text_id, sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 450, 10000)]      0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 450, 1000)         10001000  \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 45, 1000)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 45000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 45001     \n",
      "=================================================================\n",
      "Total params: 10,046,001\n",
      "Trainable params: 10,046,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def text_matrix_seq(text_id, sense, data_set = \"train\"): # this method is creating a matrix for input\n",
    "    text = all_text[data_set][sense][text_id]\n",
    "    N = len(text)\n",
    "    if N <= 450: # in case if we have less words than 450 in one text\n",
    "        text_array = np.zeros((450, NNN))\n",
    "    else:\n",
    "        text_array = np.zeros((450, NNN))\n",
    "        N = 450\n",
    "    for i in range(N):\n",
    "        if text[i] in top_5K.keys(): # put 1 in the matrix according to order in top 5k if word is there\n",
    "            index = top_5K[text[i]]\n",
    "            text_array[i,index] = 1\n",
    "    seqq = np.zeros((450,NNN))\n",
    "    seqq[0:449,] = text_array[1:450,]\n",
    "    final = np.concatenate((text_array, seqq), axis = 1) # concatenating 2 vectors (consequtive 2 words in text)\n",
    "    # in a way that 2 words merged together in one line, so length of the vector doubled in each row\n",
    "    # and repeating it for all words in the text\n",
    "    return final\n",
    "\n",
    "       \n",
    "def one_text_generator_2():\n",
    "    text_id, sense = text_selection_train() # selecting a document/text\n",
    "    #print(text_id)\n",
    "    text_array = text_matrix_seq(text_id[0], sense) # obtaining a matrix for input\n",
    "    if sense == 'pos':\n",
    "        sense = 1\n",
    "    else:\n",
    "        sense = 0\n",
    "    return text_array, sense   \n",
    "\n",
    "def model2(ff,kk,ss,pp): # function which creates a model\n",
    "    inputs = tf.keras.layers.Input( shape=(450,NNN*2), dtype=tf.float32)\n",
    "    #inputs = tf.keras.Sequential()\n",
    "    x = tf.keras.layers.Conv1D(filters=ff,kernel_size=kk,strides=ss, activation='relu', padding =\"SAME\")(inputs)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=pp)(x)#tf.keras.layers.Lambda(max_pool=4)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(inputs = inputs, outputs = x)\n",
    "\n",
    "net_conv2 = model2(1000,1,1,10) # creating a model\n",
    "net_conv2.summary()\n",
    "loss_object =  tf.keras.losses.BinaryCrossentropy(from_logits =True) # loss function\n",
    "net_conv2_optimizer =tf.keras.optimizers.Adam(2e-4, beta_1=0.5) # optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(one_text, target):\n",
    "    # function for training, we are traing one text per session\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = net_conv2(one_text,training=True) \n",
    "        loss = loss_object(target, prediction)\n",
    "        gradients = tape.gradient(loss, net_conv2.trainable_weights)\n",
    "        net_conv2_optimizer.apply_gradients(zip(gradients, net_conv2.trainable_weights))\n",
    "        return loss\n",
    "\n",
    "def fit_function(steps = 5000):\n",
    "    losses = [] # loss history\n",
    "    for step in tqdm(range(steps)):\n",
    "        \n",
    "        one_text, target = one_text_generator_2() # generating an input\n",
    "        \n",
    "        #print(\"len text: \", len(one_text))\n",
    "        one_text, target = tf.cast(one_text, tf.float32),tf.cast(target, tf.float32)\n",
    "        one_text, target = tf.expand_dims(one_text, 0),tf.expand_dims(target, 0)\n",
    "        loss = train_step(one_text, target) # training\n",
    "        losses.append(loss.numpy())\n",
    "        #print(\"Loss: \", loss.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1f5ad076904902885ef09a9b8c43dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd722071a90>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses2 = fit_function()\n",
    "loss_pd = pd.Series(losses2).ewm(halflife=50)\n",
    "plt.plot(loss_pd.mean())\n",
    "plt.plot(losses2, 'b', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test of seq-CNN\n",
    "In this step we tested trained above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(): # testing part\n",
    "    targets=[]\n",
    "    answ = []\n",
    "    step =len(test_set)\n",
    "    steps = np.random.choice(range(len(test_set)),1500) # choosing random 1500 texts from test set\n",
    "    for i in tqdm(steps):    \n",
    "        text_id, sense = test_set[i], target_label[i]\n",
    "        #print(text_id)\n",
    "        target = sense\n",
    "        if sense == 1:\n",
    "            sense = 'pos'\n",
    "        else:\n",
    "            sense = 'neg'\n",
    "        one_text = text_matrix_seq(text_id, sense, data_set=\"test\")\n",
    "        one_text = tf.cast(one_text, tf.float32)\n",
    "        one_text= tf.expand_dims(one_text, 0)\n",
    "        answ.append(int(round(net_conv2.predict(one_text)[0][0]))) # predicting\n",
    "        targets.append(target)\n",
    "    #print(answ)\n",
    "    print(np.sum(targets)) # the number of positive comments # just to be sure that data is balanced\n",
    "    #print(answ)\n",
    "    #print(targets)\n",
    "    answ = np.array(answ)\n",
    "    targets = np.array(targets)\n",
    "    print (np.sum(np.array((answ - targets))**2)/len(steps)) # error rate\n",
    "    return (pred_error(targets,answ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57ea22727c64279b8bab36e317809b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "776\n",
      "0.17133333333333334\n"
     ]
    }
   ],
   "source": [
    "(err, conf_mat, accuracy)=testing()\n",
    "# 776 it is the number of positive comments that model predicted # just to be sure that targets are balanced\n",
    "# then this function is printing error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286666666666667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy # accuracy value on the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bow-CNN\n",
    "#### second model\n",
    "\n",
    "The main difference from the first model is that input size is less for 2 times because we are not concatenating matrixes. And kernel size is 2 in convolutional layer. In order to make as an input for the convolutional layer the pair of consequtive words but without saving the order. However, according to the paper order is saved since we are considering consequrive pairs. All the procedures in this section are the same as in the previous except for matrix maker function. Additionally, we are giving different parameters to a model. Sequences of words considered here as in the picture below:\n",
    "\n",
    "![bow](bow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_matrix_BOW(text_id, sense, data_set = \"train\"):\n",
    "    text = all_text[data_set][sense][text_id]\n",
    "    N = len(text)\n",
    "    if N <= 450:\n",
    "        text_array = np.zeros((450, NNN))\n",
    "    else:\n",
    "        text_array = np.zeros((450, NNN))\n",
    "        N = 450\n",
    "    for i in range(N):\n",
    "        if text[i] in top_5K.keys():\n",
    "            index = top_5K[text[i]]\n",
    "            text_array[i,index] = 1\n",
    "    return text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "def one_text_generator():\n",
    "    text_id, sense = text_selection_train()\n",
    "    #print(text_id)\n",
    "    text_array = text_matrix_BOW(text_id[0], sense)\n",
    "    if sense == 'pos':\n",
    "        sense = 1\n",
    "    else:\n",
    "        sense = 0\n",
    "    return text_array, sense   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(ff,kk,ss,pp):\n",
    "    inputs = tf.keras.layers.Input( shape=(450,NNN), dtype=tf.float32)\n",
    "    #inputs = tf.keras.Sequential()\n",
    "    x = tf.keras.layers.Conv1D(filters=ff,kernel_size=kk,strides=ss, activation='relu', padding =\"SAME\")(inputs)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=pp)(x)#tf.keras.layers.Lambda(max_pool=4)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(inputs = inputs, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 450, 5000)]       0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 450, 1000)         10001000  \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 45, 1000)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 45000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 45001     \n",
      "=================================================================\n",
      "Total params: 10,046,001\n",
      "Trainable params: 10,046,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net_conv = model(1000,2,1,10) # BOW\n",
    "net_conv.summary()\n",
    "loss_object =  tf.keras.losses.BinaryCrossentropy(from_logits =True)\n",
    "net_conv_optimizer =tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(one_text, target):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = net_conv(one_text,training=True) \n",
    "        loss = loss_object(target, prediction)\n",
    "        gradients = tape.gradient(loss, net_conv.trainable_weights)\n",
    "        net_conv_optimizer.apply_gradients(zip(gradients, net_conv.trainable_weights))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_function(steps = 5000):\n",
    "    losses = []\n",
    "    for step in tqdm(range(steps)):\n",
    "        \n",
    "        one_text, target = one_text_generator()\n",
    "        \n",
    "        #print(\"len text: \", len(one_text))\n",
    "        one_text, target = tf.cast(one_text, tf.float32),tf.cast(target, tf.float32)\n",
    "        one_text, target = tf.expand_dims(one_text, 0),tf.expand_dims(target, 0)\n",
    "        loss = train_step(one_text, target)\n",
    "        losses.append(loss.numpy())\n",
    "        #print(\"Loss: \", loss.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c318635dbffc4b6b9a3089c8e90b36ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = fit_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0c9c241710>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_pd = pd.Series(losses).ewm(halflife=50)\n",
    "plt.plot(loss_pd.mean())\n",
    "plt.plot(losses, 'b', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test of bow-CNN\n",
    "testing of the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing():\n",
    "    targets=[]\n",
    "    answ = []\n",
    "    step =len(test_set)\n",
    "    steps = np.random.choice(range(len(test_set)),1500)\n",
    "    for i in tqdm(steps):    \n",
    "        text_id, sense = test_set[i], target_label[i]\n",
    "        #print(text_id)\n",
    "        target = sense\n",
    "        if sense == 1:\n",
    "            sense = 'pos'\n",
    "        else:\n",
    "            sense = 'neg'\n",
    "        one_text = text_matrix_BOW(text_id, sense, data_set=\"test\")\n",
    "        one_text = tf.cast(one_text, tf.float32)#,tf.cast(target, tf.float32)\n",
    "        one_text= tf.expand_dims(one_text, 0)#,tf.expand_dims(target, 0)\n",
    "        answ.append(int(round(net_conv.predict(one_text)[0][0])))\n",
    "        targets.append(target)\n",
    "    #print(answ)\n",
    "    print(np.sum(targets))\n",
    "    #print(answ)\n",
    "    #print(targets)\n",
    "    answ = np.array(answ)\n",
    "    targets = np.array(targets)\n",
    "    print (np.sum(np.array((answ - targets))**2)/len(steps))\n",
    "    return (pred_error(targets,answ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b544e1bb8144fcab47008c6ce5e79b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "776\n",
      "0.16866666666666666\n"
     ]
    }
   ],
   "source": [
    "(err, conf_mat, accuracy)=testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8313333333333334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Experimental evaluation\n",
    "\n",
    "Two experiments were performed in this project using Tensorflow. In both cases structure of the Network was similar. They had several layers: input, convolution, pooling, output layers.\n",
    "\n",
    "Their differences were in the dimension of the input and parameters of the model such as filters number, kernel size. \n",
    "\n",
    "In the paper authors implemented dynamic maxpooling layer without changing texts matrixes dimension. According to them in their network it was possible to put the inputs with different dimensions. I tryed to do it also in Tensorflow but I had warning message that graph was changed(retracing). That is why I decided to look at the lengthes of the texts and then I took the 450 as the value as a maximum length of my input because this value is more than the 95% quantile of lenthes. Because of it my network stopped to produce warnings.\n",
    "\n",
    "In the paper a lot of experiments were described but since I was doing this project alone I decided to perform only two examples of them.\n",
    "\n",
    "In the results of the paper error rate was close to 10%. I obtained value close to 20% in both cases which is not that bad if we take into consideration that I took only 5k words instead of 30k as authors did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the code below you can see my trial to implement dynamic maxpooling using Lambda function in tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_poolling(inputs, max_pool_units = 75, filter_n = 32):\n",
    "    shape = inputs.shape\n",
    "    if shape[1] is None:\n",
    "        return tf.keras.layers.Input((75,32))\n",
    "    else:\n",
    "        if shape[1]%max_pool_units==0:\n",
    "            window_size= shape[1]//max_pool_units\n",
    "\n",
    "        else:\n",
    "            window_size= shape[1]//max_pool_units +1\n",
    "            adder =max_pool_units-shape[1]%max_pool_units\n",
    "            add_array = tf.zeros((adder, filter_n))\n",
    "            add_array = tf.expand_dims(add_array, 0)\n",
    "            #print(add_array)\n",
    "            inputs = tf.concat([inputs, add_array], 1) #otmetka 0\n",
    "\n",
    "        shape = inputs.shape \n",
    "        #print(shape)\n",
    "        x =tf.reshape(inputs, shape=(1, int(shape[1]/window_size), window_size, 32 )) #[300,32] = [75,4,32]\n",
    "        x_max = tf.reduce_max(x, axis=1) #[1,75,1,32], \n",
    "        #x_max = tf.expand_dims(x_max, 0)\n",
    "        #x_max =tf.squeeze(x_max) #[1,75,32]\n",
    "        #print(\"x_maxpool: \", x_max.shape)\n",
    "        return x_max\n",
    "def model():\n",
    "    inputs = tf.keras.layers.Input( shape=(None,5000), dtype=tf.float32)\n",
    "    #inputs = tf.keras.Sequential()\n",
    "    x = tf.keras.layers.Conv1D(filters=32,kernel_size=2,strides=1, activation='relu', padding =\"SAME\")(inputs)\n",
    "    x = tf.keras.layers.Lambda(max_poolling)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(inputs = inputs, outputs = x)\n",
    "net_conv = model()\n",
    "net_conv.summary()\n",
    "loss_object =  tf.keras.losses.BinaryCrossentropy(from_logits =True)\n",
    "net_conv_optimizer =tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
